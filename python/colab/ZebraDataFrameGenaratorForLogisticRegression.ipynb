{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZebraDataFrameGenaratorForLogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8K01RvjYYyBH",
        "1MEAzu41Y4km",
        "3iDrfZiRO-jV",
        "ukmjlSiAXlnu",
        "u2jZBu5-ZKMj",
        "sxdZg95fO3X8",
        "KA208Fm-13CJ",
        "gZGZTRzpZceU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkmkGUQ3EgoZ"
      },
      "source": [
        "# Zebra **DataFrame** generation from `event.csv` files for **Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K01RvjYYyBH"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utV9rj1jNn0F"
      },
      "source": [
        "#######################\n",
        "#       IMPORTS       #\n",
        "#######################\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "import copy\n",
        "import re\n",
        "import sys\n",
        "import getopt\n",
        "import matplotlib as mpl\n",
        "mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import getpass\n",
        "\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "from shutil import copyfile\n",
        "from scipy.integrate import simps\n",
        "\n",
        "outputDataList = []\n",
        "\n",
        "TSV_IMPACT = 24.5\n",
        "TSV_FREEFALL = 5.8\n",
        "TSV_CALMZONE_HIGH = 11\n",
        "TSV_CALMZONE_MEDIUM = 10\n",
        "TSV_CALMZONE_LOW = 8\n",
        "TSV_FREEFALL_SPIN = 4\n",
        "\n",
        "DTSV_IMPACT_LOW = 10\n",
        "DTSV_IMPACT_MEDIUM = 14.7\n",
        "DTSV_IMPACT_HIGH = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MEAzu41Y4km"
      },
      "source": [
        "### Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNFdUrv5PUQH"
      },
      "source": [
        "#######################\n",
        "#       SCALARS       #\n",
        "#######################\n",
        "EVENT_IMPACT = 1\n",
        "EVENT_FREEFALL = 2\n",
        "\n",
        "TYPE_UNKNOWN = 0\n",
        "TYPE_FREEFALL_SIGNIFICANT = 1\n",
        "TYPE_FREEFALL_INSIGNIFICANT = 2\n",
        "TYPE_IMPACT_NEGLIGIBLE = 1\n",
        "TYPE_IMPACT_SOFT = 2\n",
        "TYPE_IMPACT_MEDIUM = 3\n",
        "TYPE_IMPACT_HARD = 4\n",
        "TYPE_IMPACT_FORCE = 5\n",
        "\n",
        "TSV_IMPACT = 24.5\n",
        "TSV_FREEFALL = 5.8\n",
        "TSV_CALMZONE_HIGH = 11\n",
        "TSV_CALMZONE_MEDIUM = 10\n",
        "TSV_CALMZONE_LOW = 8\n",
        "TSV_FREEFALL_SPIN = 4\n",
        "\n",
        "DTSV_IMPACT_LOW = 10\n",
        "DTSV_IMPACT_MEDIUM = 14.7\n",
        "DTSV_IMPACT_HIGH = 20\n",
        "\n",
        "interpolateFreq = 10\n",
        "resampleFactor = 2\n",
        "\n",
        "ZONE_PREFALL = 1\n",
        "ZONE_FREEFALL = 2\n",
        "ZONE_IMPACT = 3\n",
        "ZONE_NOISE = 4\n",
        "ZONE_CALM = 0\n",
        "\n",
        "PREFALL_LENGTH = 200\n",
        "PREIMPACT_LENGTH = 100\n",
        "FREEFALL_SIGNIFICANT = 200\n",
        "CALMZONE_DURATION = 30\n",
        "IMPACT_LENGTH_MIN = 60\n",
        "FORCE_AREA_MIN = 600\n",
        "EVENT_GAP_MIN = 30\n",
        "\n",
        "prefallTypes = [\n",
        "    [\"FFXP\",\"a freefall on its left side\"],\n",
        "    [\"FFXM\",\"a freefall on its right side\"],\n",
        "    [\"FFYP\",\"a freefall on its bottom\"],\n",
        "    [\"FFYM\",\"a freefall on its top\"],\n",
        "    [\"FFZP\",\"a freefall while facing down\"],\n",
        "    [\"FFZM\",\"a freefall while facing up\"],\n",
        "    [\"HFXP\",\"a freefall following a push on its left side\"],\n",
        "    [\"HFXM\",\"a freefall following a push on its right side\"],\n",
        "    [\"HFYP\",\"a freefall following a push on its bottom\"],\n",
        "    [\"HFYM\",\"a freefall following a push on its top\"],\n",
        "    [\"HFZP\",\"a freefall following a push on its face\"],\n",
        "    [\"HFZM\",\"a freefall following a push on its back\"],\n",
        "    [\"OTXX\",\"an overhand throw\"],\n",
        "    [\"UTXX\",\"an underhand throw\"],\n",
        "    [\"PFXX\",\"a slippage while being put into pocket\"],\n",
        "    [\"PPXX\",\"a slippage while being put into pocket\"],\n",
        "    [\"TCXX\",\"an upward throw\"]\n",
        "    ]\n",
        "\n",
        "impactTypes = [\n",
        "    [\"DSXX\",\"was slammed on the desk\"],\n",
        "    [\"WSXX\",\"hit a wall\"],\n",
        "    [\"FSXX\",\"was slammed on the floor\"]\n",
        "    ]\n",
        "\n",
        "imageTypes = [\n",
        "    [\"FFXP\",\"img/DAFall.png\"],\n",
        "    [\"FFXM\",\"img/DAFall.png\"],\n",
        "    [\"FFYP\",\"img/DAFall.png\"],\n",
        "    [\"FFYM\",\"img/DAFall.png\"],\n",
        "    [\"FFZP\",\"img/DAFall.png\"],\n",
        "    [\"FFZM\",\"img/DAFall.png\"],\n",
        "    [\"HFXP\",\"img/DATableFall.png\"],\n",
        "    [\"HFXM\",\"img/DATableFall.png\"],\n",
        "    [\"HFYP\",\"img/DATableFall.png\"],\n",
        "    [\"HFYM\",\"img/DATableFall.png\"],\n",
        "    [\"HFZP\",\"img/DATableFall.png\"],\n",
        "    [\"HFZM\",\"img/DATableFall.png\"],\n",
        "    [\"OTXX\",\"img/DAOThrow.png\"],\n",
        "    [\"UTXX\",\"img/DAUThrow.png\"],\n",
        "    [\"PFXX\",\"img/DAPocketSlip.png\"],\n",
        "    [\"PPXX\",\"img/DAPocketSlip.png\"],\n",
        "    [\"TCXX\",\"img/DAThrowCatch.png\"],\n",
        "    [\"DSXX\",\"img/DADeskSlam.png\"],\n",
        "    [\"WSXX\",\"img/DAWallSlam.png\"],\n",
        "    [\"FSXX\",\"img/DAFloorSlam.png\"]\n",
        "    ]\n",
        "\n",
        "outputDataList = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iDrfZiRO-jV"
      },
      "source": [
        "### Helper Methods\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_fVag9oOY4z"
      },
      "source": [
        "#######################\n",
        "#       HELPERS       #\n",
        "#######################\n",
        "def addEvent (eventType, eventStart, eventEnd):\n",
        "    # Create new event\n",
        "    processedEvent.append([eventType, False, 0, 0, eventStart, eventEnd, 0, 0, \"\"])\n",
        "    \n",
        "    currentIndex = len(processedEvent) - 1\n",
        "\n",
        "    # Detect duration\n",
        "\n",
        "    # Detect significance\n",
        "\n",
        "    # \n",
        "    return currentIndex\n",
        "\n",
        "def findEvent (eventType, eventStart):\n",
        "    eventIndex = 0\n",
        "\n",
        "    return int(eventIndex)\n",
        "\n",
        "def updateEventValue (eventIndex, updateIndex, newValue):\n",
        "\n",
        "    return\n",
        "\n",
        "def updateEventCause (eventIndex, newCause):\n",
        "    return updateEventValue(eventIndex, INDEX_EVENT_CAUSE, newCause)\n",
        "\n",
        "\"\"\"\n",
        "This function fills in missing data for prefall and preimpact analysis\n",
        "    Input:\n",
        "        (1: list) Actual dataset\n",
        "        (2: int) Start of data\n",
        "        (3: int) End of data\n",
        "        (4: int) Required length\n",
        "    Output:\n",
        "        (1: list) Filled-in dataset\n",
        "\"\"\"\n",
        "def fillData (origDataset, start, end, length):\n",
        "    finalDataset = list()\n",
        "    if (length > (end - start)):\n",
        "        fillNeed = length - (end - start)\n",
        "    else:\n",
        "        fillNeed = 0\n",
        "    for i in range(fillNeed):\n",
        "        finalDataset.append(origDataset[start])\n",
        "    for i in range(start, end):\n",
        "        finalDataset.append(origDataset[i])\n",
        "\n",
        "    return finalDataset\n",
        "\n",
        "\"\"\"\n",
        "This function estimates fall height from fall duration.\n",
        "    Input:\n",
        "        (1: float) Fall duration in ms\n",
        "    Output:\n",
        "        (1: float) Estimated fall height in feet\n",
        "\"\"\"\n",
        "def estimateDistance (durarion = 0):\n",
        "    return round((3.28*(9.81*(durarion/1000)*(durarion/1000))/2) * 1.225, 2)\n",
        "\n",
        "\"\"\"\n",
        "This function detects spin in a freefall.\n",
        "    Input:\n",
        "        (1: list) TSV dataset\n",
        "        (2: int) Freefall start index\n",
        "        (3: int) Freefall end index\n",
        "    Output:\n",
        "        (1: Bool) True if spin detected, False otherwise\n",
        "\"\"\"\n",
        "def detectSpin (tsvDataset, start, end):\n",
        "    detected = False\n",
        "    for i in range(start, end):\n",
        "        if (tsvDataset[i] >= TSV_FREEFALL_SPIN):\n",
        "            detected = True\n",
        "            break\n",
        "    \n",
        "    return detected\n",
        "\n",
        "\"\"\"\n",
        "This function detects impact orientation.\n",
        "    Input:\n",
        "        (1: list) TSV dataset\n",
        "        (2: list) X dataset\n",
        "        (3: list) Y dataset\n",
        "        (4: list) Z dataset\n",
        "        (5: int) Impact start index\n",
        "        (6: int) Impact end index\n",
        "    Output:\n",
        "        (1: list) Relative components (in %) of TSV in each 3 direction\n",
        "\"\"\"\n",
        "def detectImpactDirection (tsvDataset, xDataset, yDataset, zDataset, start, end):\n",
        "    xComponent = 0\n",
        "    yComponent = 0\n",
        "    zComponent = 0\n",
        "\n",
        "    maxTsv = -1\n",
        "    maxI = -1\n",
        "\n",
        "    for i in range(start, end):\n",
        "        if (tsvDataset[i] > maxTsv):\n",
        "            maxTsv = tsvDataset[i]\n",
        "            maxI = i\n",
        "\n",
        "    if (maxI >= 0):\n",
        "\n",
        "        # Values\n",
        "        xComponent = round((xDataset[maxI] * xDataset[maxI] * 100) / (tsvDataset[maxI] * tsvDataset[maxI]), 2)\n",
        "        yComponent = round((yDataset[maxI] * yDataset[maxI] * 100) / (tsvDataset[maxI] * tsvDataset[maxI]), 2)\n",
        "        zComponent = round((zDataset[maxI] * zDataset[maxI] * 100) / (tsvDataset[maxI] * tsvDataset[maxI]), 2)\n",
        "\n",
        "        # Signs\n",
        "        if (xDataset[maxI] < 0):\n",
        "            xComponent = -xComponent\n",
        "\n",
        "        if (yDataset[maxI] < 0):\n",
        "            yComponent = -yComponent\n",
        "\n",
        "        if (zDataset[maxI] < 0):\n",
        "            zComponent = -zComponent\n",
        "        \n",
        "    return [xComponent, yComponent, zComponent]\n",
        "\n",
        "\"\"\"\n",
        "This function merges closely spaced similar events to handle in-event noises.\n",
        "    Input:\n",
        "        (1: list) Events' list\n",
        "    Output:\n",
        "        (1: list) Merged events' list\n",
        "\"\"\"\n",
        "def mergeEvents(events):\n",
        "    mergedEvents = list()\n",
        "\n",
        "    if (len(events) <= 1):\n",
        "        return events\n",
        "\n",
        "    i = 0\n",
        "    continued = False\n",
        "    while (i < len(events)):\n",
        "        if (i == (len(events) - 1)):\n",
        "            # We're at last event\n",
        "            if not (continued):\n",
        "                currentEvent = events[i]\n",
        "            else:\n",
        "                i -= 1\n",
        "                continued = False\n",
        "        else:\n",
        "            if (continued):\n",
        "                nextEvent = events[i]\n",
        "            else:\n",
        "                currentEvent = events[i]\n",
        "                nextEvent = events[i + 1]\n",
        "                i += 1\n",
        "\n",
        "            if (nextEvent[0] == currentEvent[0]):\n",
        "                # The two events are same\n",
        "                if ((nextEvent[1] - currentEvent[2]) < EVENT_GAP_MIN):\n",
        "                    # Too closely spaced, merge\n",
        "                    currentEvent[2] = nextEvent[2]\n",
        "                    if (currentEvent[0] == EVENT_IMPACT):\n",
        "                        currentEvent[3] = max(currentEvent[3], nextEvent[3])\n",
        "                        currentEvent[4] = max(currentEvent[4], nextEvent[4])\n",
        "                        currentEvent[5] = max(currentEvent[5], nextEvent[5])\n",
        "                    elif (currentEvent[0] == EVENT_FREEFALL):\n",
        "                        currentEvent[3] = min(currentEvent[3], nextEvent[3])\n",
        "                        currentEvent[4] = currentEvent[4] or nextEvent[4]\n",
        "                    continued = True\n",
        "                else:\n",
        "                    continued = False\n",
        "                    i -= 1\n",
        "            else:\n",
        "                continued = False\n",
        "                i -= 1\n",
        "        i += 1\n",
        "        if not (continued):\n",
        "            mergedEvents.append(currentEvent)\n",
        "    return mergedEvents\n",
        "\n",
        "\"\"\"\n",
        "This function parses a list of events and prints the results\n",
        "    Input:\n",
        "        (1: list) Event list\n",
        "        (2: list) Timestamp dataset\n",
        "    Output:\n",
        "        Nothing\n",
        "\"\"\"\n",
        "def parseEvents (eventList, tsDataset):\n",
        "    if (debugMode):\n",
        "        for event in eventList:\n",
        "            print(event)\n",
        "\n",
        "    lastEvent = 0\n",
        "    for event in eventList:\n",
        "        if (event[0] == EVENT_FREEFALL):\n",
        "            if (event[4]):\n",
        "                spinResult = \"Yes\"\n",
        "            else:\n",
        "                spinResult = \"No\"\n",
        "            print(\"After\", format(event[1] - lastEvent, '.2f'), \"ms:\", \"Freefall of duration\", format(tsDataset[event[2]] - tsDataset[event[1]], '.2f'), \"ms, minimum TSV:\", format(event[3], '.2f'), \"m/s2, estimated fall:\", estimateDistance(tsDataset[event[2]] - tsDataset[event[1]]), \"feet, spin detected:\", spinResult)\n",
        "        elif(event[0] == EVENT_IMPACT):\n",
        "            if (event[5] == TYPE_IMPACT_HARD):\n",
        "                impactType = \"Severe\"\n",
        "            elif (event[5] == TYPE_IMPACT_MEDIUM):\n",
        "                impactType = \"Medium\"\n",
        "            elif (event[5] == TYPE_IMPACT_SOFT):\n",
        "                impactType = \"Low\"\n",
        "            elif (event[5] == TYPE_IMPACT_FORCE):\n",
        "                impactType = \"Force\"\n",
        "            else:\n",
        "                impactType = \"Negligible\"\n",
        "            print(\"After\", format(event[1] - lastEvent, '.2f'), \"ms:\", \"Impact of duration\", format(tsDataset[event[2]] - tsDataset[event[1]], '.2f'), \"ms, maximum TSV:\", format(event[3], '.2f'), \"m/s2, maximum DTSV:\", event[4], \", type:\", impactType)\n",
        "            print(\"Impact direction =\", detectImpactDirection (tsvResampled, xResampled, yResampled, zResampled, event[1], event[2]))\n",
        "        else:\n",
        "            print(\"After\", format(event[1] - lastEvent, '.2f'), \"ms:\", \"Unknown event of duration\", format(tsDataset[event[2]] - tsDataset[event[1]], '.2f'), \"ms\")\n",
        "        lastEvent = event[2]\n",
        "    return\n",
        "\n",
        "def prefallProcess(xData, yData, zData, zoneStart, zoneEnd):\n",
        "    finalDF = pd.DataFrame()\n",
        "    \n",
        "    rowCount = zoneEnd - zoneStart\n",
        "    count = 0\n",
        "       \n",
        "    if (rowCount >= PREFALL_LENGTH):\n",
        "        start = 0\n",
        "        end = rowCount\n",
        "       \n",
        "        for i in range(start, end):\n",
        "            temp = pd.DataFrame(columns=['X'+str(i), 'Y'+str(i), 'Z'+str(i)])\n",
        "            temp.loc[0] = [xData[i], yData[i], zData[i]]\n",
        "            temp = temp.reset_index(drop=True)\n",
        "           \n",
        "            if count == 0:\n",
        "                tempDF = temp\n",
        "                count = 1\n",
        "            else:\n",
        "                tempDF = pd.concat([tempDF.reset_index(drop=True), temp], axis=1)\n",
        "               \n",
        "        finalDF = finalDF.append(tempDF)\n",
        "    elif (rowCount >= PREFALL_LENGTH / 2):\n",
        "        # Not enough data, but still try with padding\n",
        "        diff = PREFALL_LENGTH - rowCount\n",
        "        start = 0\n",
        "        end = PREFALL_LENGTH\n",
        "        countDown = PREFALL_LENGTH - rowCount\n",
        "        \n",
        "        for i in range(start, end):\n",
        "            temp = pd.DataFrame(columns=['X'+str(i), 'Y'+str(i), 'Z'+str(i)])\n",
        "            if (countDown > 0):\n",
        "                temp.loc[0] = [xData[0], yData[0], zData[0]]\n",
        "                countDown -= 1\n",
        "            else:\n",
        "                temp.loc[0] = [xData[i - diff], yData[i - diff], zData[i - diff]]\n",
        "            temp = temp.reset_index(drop=True)\n",
        "           \n",
        "            if count == 0:\n",
        "                tempDF = temp\n",
        "                count = 1\n",
        "            else:\n",
        "                tempDF = pd.concat([tempDF.reset_index(drop=True), temp], axis=1)\n",
        "               \n",
        "        finalDF = finalDF.append(tempDF)\n",
        "    else:\n",
        "        # Not nearly enough data\n",
        "        print(\"Cannot do prefall analysis. Number of samples is less than\", PREFALL_LENGTH)\n",
        "    return finalDF\n",
        "\n",
        "def preimpactProcess(xData, yData, zData, zoneStart, zoneEnd):\n",
        "    finalDF = pd.DataFrame()\n",
        "    \n",
        "    rowCount = zoneEnd - zoneStart\n",
        "    count = 0\n",
        "       \n",
        "    if (rowCount >= PREIMPACT_LENGTH):\n",
        "        start = 0\n",
        "        end = rowCount\n",
        "       \n",
        "        for i in range(start, end):\n",
        "            temp = pd.DataFrame(columns=['X'+str(i), 'Y'+str(i), 'Z'+str(i)])\n",
        "            temp.loc[0] = [xData[i], yData[i], zData[i]]\n",
        "            temp = temp.reset_index(drop=True)\n",
        "           \n",
        "            if count == 0:\n",
        "                tempDF = temp\n",
        "                count = 1\n",
        "            else:\n",
        "                tempDF = pd.concat([tempDF.reset_index(drop=True), temp], axis=1)\n",
        "               \n",
        "        finalDF = finalDF.append(tempDF)\n",
        "    elif (rowCount >= PREIMPACT_LENGTH / 2):\n",
        "        # Not enough data, but still try with padding\n",
        "        diff = PREIMPACT_LENGTH - rowCount\n",
        "        start = 0\n",
        "        end = PREIMPACT_LENGTH\n",
        "        countDown = PREIMPACT_LENGTH - rowCount\n",
        "        \n",
        "        for i in range(start, end):\n",
        "            temp = pd.DataFrame(columns=['X'+str(i), 'Y'+str(i), 'Z'+str(i)])\n",
        "            if (countDown > 0):\n",
        "                temp.loc[0] = [xData[0], yData[0], zData[0]]\n",
        "                countDown -= 1\n",
        "            else:\n",
        "                temp.loc[0] = [xData[i - diff], yData[i - diff], zData[i - diff]]\n",
        "            temp = temp.reset_index(drop=True)\n",
        "           \n",
        "            if count == 0:\n",
        "                tempDF = temp\n",
        "                count = 1\n",
        "            else:\n",
        "                tempDF = pd.concat([tempDF.reset_index(drop=True), temp], axis=1)\n",
        "               \n",
        "        finalDF = finalDF.append(tempDF)\n",
        "    else:\n",
        "        # Not nearly enough data\n",
        "        print(\"Cannot do prefall analysis. Number of samples is less than\", PREIMPACT_LENGTH)\n",
        "    return finalDF\n",
        "\n",
        "def convertEventCode(eventCode):\n",
        "    for event in prefallTypes:\n",
        "        if (event[0] == eventCode):\n",
        "            return event[1]\n",
        "\n",
        "    for event in impactTypes:\n",
        "        if (event[0] == eventCode):\n",
        "            return event[1]\n",
        "\n",
        "    return \"Unknown event\"\n",
        "\n",
        "def getImageName(eventCode):\n",
        "    for event in imageTypes:\n",
        "        if (event[0] == eventCode):\n",
        "            return event[1]\n",
        "\n",
        "    return \"Unknown.png\"\n",
        "\n",
        "def detectType(eventList, fallNum, impactNum, fallType, impactTypes):\n",
        "    impactResult = \"\"\n",
        "    freefallResult = \"\"\n",
        "    result = \"The device\"\n",
        "    firstFall = True\n",
        "    firstImpact = True\n",
        "    imageFileName = \"img/Unknown.png\"\n",
        "\n",
        "    if (fallNum + impactNum == 0):\n",
        "        result = result + \" did not suffer any major abuse\"\n",
        "        impactResult = \"No significant impacts detected\"\n",
        "        freefallResult = \"No significant freefalls detected\"\n",
        "        return freefallResult, impactResult, result, imageFileName\n",
        "    \n",
        "    if (fallNum == 0):\n",
        "        result = result + \" did not have a significant fall\"\n",
        "    elif (fallNum == 1):\n",
        "        if (len(fallType) == 0):\n",
        "            result = result + \" fell down once\"\n",
        "        else:\n",
        "            result = result + \" suffered \" + convertEventCode(fallType)\n",
        "            imageFileName = getImageName(fallType)\n",
        "    else:\n",
        "        if (len(fallType) == 0):\n",
        "            result = result + \" fell down \" + str(fallNum) + \" time(s)\"\n",
        "        else:\n",
        "            result = result + \" suffered \" + convertEventCode(fallType)\n",
        "            imageFileName = getImageName(fallType)\n",
        "\n",
        "    if (impactNum == 0):\n",
        "        result = result + \", but did not hit anything hard.\"\n",
        "    else:\n",
        "        if (fallNum == 0):\n",
        "            result = result + \", but \"\n",
        "            if(len(impactTypes[0]) > 0):\n",
        "                result = result + convertEventCode(impactTypes[0])\n",
        "                imageFileName = getImageName(impactTypes[0])\n",
        "        else:\n",
        "            result = result + \", and \"\n",
        "            if (impactNum == 1):\n",
        "                result = result + \"hit a surface.\"\n",
        "            elif (impactNum == 2):\n",
        "                result = result + \"there were a couple of impacts.\"\n",
        "            elif (impactNum > 2):\n",
        "                result = result + \"there were multiple impacts (\" + str(impactNum) + \")\"       \n",
        "\n",
        "    for event in eventList:\n",
        "        if (event[0] == EVENT_FREEFALL):\n",
        "            if (event[4]):\n",
        "                spinResult = \"Yes\"\n",
        "            else:\n",
        "                spinResult = \"No\"\n",
        "            if (firstFall):\n",
        "                firstFall = False\n",
        "            else:\n",
        "                freefallResult = freefallResult + \"<br><br>\"\n",
        "            freefallResult = freefallResult + \"<b>Freefall</b> of duration \" + str(round(tsResampled[event[2]] - tsResampled[event[1]], 2)) + \" ms<br>Minimum TSV: \" + str(round(event[3], 2))  + \" m/s2<br>Estimated fall height: \" + str(round(estimateDistance(tsResampled[event[2]] - tsResampled[event[1]]), 2)) + \" feet<br>Spin detected: \" + spinResult\n",
        "        elif (event[0] == EVENT_IMPACT):\n",
        "            if (firstImpact):\n",
        "                firstImpact = False\n",
        "            else:\n",
        "                impactResult = impactResult + \"<br><br>\"\n",
        "            if (event[5] == TYPE_IMPACT_FORCE):\n",
        "                impactResult = impactResult + \"<b>Force</b> impartion of duration \" + str(round(tsResampled[event[2]] - tsResampled[event[1]], 2)) + \" ms<br>Maximum TSV: \" + str(round(event[3], 2)) + \" m/s2\"\n",
        "            else:\n",
        "                if (event[5] == TYPE_IMPACT_HARD):\n",
        "                    impactType = \"Severe\"\n",
        "                elif (event[5] == TYPE_IMPACT_MEDIUM):\n",
        "                    impactType = \"Medium\"\n",
        "                elif (event[5] == TYPE_IMPACT_SOFT):\n",
        "                    impactType = \"Low\"\n",
        "                else:\n",
        "                    impactType = \"Negligible\"\n",
        "                impactResult = impactResult + \"<b>Impact</b> of duration \" + str(round(tsResampled[event[2]] - tsResampled[event[1]], 2)) + \" ms<br>Maximum TSV: \" + str(round(event[3], 2)) + \" m/s2<br>Type: \" + impactType\n",
        "\n",
        "    if (len(impactResult) == 0):\n",
        "        impactResult = \"No significant impacts detected\"\n",
        "\n",
        "    if (len(freefallResult) == 0):\n",
        "        freefallResult = \"No significant freefalls detected\"\n",
        "\n",
        "    #print(freefallResult)\n",
        "    #print(impactResult)\n",
        "    #print(result)\n",
        "\n",
        "    return freefallResult, impactResult, result, imageFileName\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KImvsVqEYZfT"
      },
      "source": [
        "#### Detect Events"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYfXReaRYTND"
      },
      "source": [
        "\"\"\"\n",
        "This function detects freefall and impact events in TSV, DTSV datasets.\n",
        "    Input:\n",
        "        (1: list) Timestamp dataset\n",
        "        (2: list) TSV dataset\n",
        "        (3: list) DTSV dataset\n",
        "    Output:\n",
        "        (1: list) Detected events\n",
        "                    Freefall: [[EVENT_FREEFALL, eventStart, eventEnd, minTsv, spinFlag]]\n",
        "                    Impact:   [[EVENT_IMPACT, eventStart, eventEnd, maxTsv, maxDtsv, impactType]]\n",
        "        (2: list) Noise zones\n",
        "                    [[noiseStart, noiseEnd]]\n",
        "    \n",
        "\"\"\"\n",
        "import pdb; \n",
        "\n",
        "def detectEvents (tsDataset, tsvDataset, dtsvDataset):\n",
        "    noiseZones = list()\n",
        "    detectedEvents = list()\n",
        "    numberOfSamples = len(tsDataset)\n",
        "\n",
        "    maxTsv = -1.0\n",
        "    minTsv = -1.0\n",
        "    freefallStart = -1\n",
        "    impactStart = -1\n",
        "    noiseStart = -1\n",
        "    calmZoneCount = 0\n",
        "    timeDiffInMs = 0\n",
        "    tsvResampled = list()\n",
        "    dtsvResampled = list()\n",
        "\n",
        "    for i in range(numberOfSamples):\n",
        "        currentTsv = tsvDataset[i]\n",
        "        # Update max/min TSV values if required\n",
        "        if (maxTsv >= 0):\n",
        "            if (maxTsv < currentTsv):\n",
        "                maxTsv = currentTsv\n",
        "        elif (minTsv >= 0):\n",
        "            if (minTsv > currentTsv):\n",
        "                minTsv = currentTsv\n",
        "\n",
        "        if (currentTsv > TSV_IMPACT):\n",
        "            # Impact zone\n",
        "            if (noiseStart >= 0):\n",
        "                calmZoneCount = 0\n",
        "            # Finalize stuff if this marks the end of a freefall event\n",
        "            if (freefallStart > 0):\n",
        "                spinDetected = detectSpin(tsvDataset, freefallStart, i)\n",
        "                detectedEvents.append([EVENT_FREEFALL, freefallStart, i, minTsv, spinDetected])\n",
        "                freefallStart = -1\n",
        "                minTsv = -1.0\n",
        "            # Initialize stuff if this is the start of impact\n",
        "            if (impactStart < 0):\n",
        "                impactStart = i\n",
        "                maxTsv = currentTsv\n",
        "        elif (currentTsv < TSV_FREEFALL):\n",
        "            # Freefall zone\n",
        "            if (noiseStart >= 0):\n",
        "                calmZoneCount = 0\n",
        "            # Finalize stuff if this marks the end of an impact event\n",
        "            if (impactStart > 0):\n",
        "                # Look at DTSV to determine type\n",
        "                maxDtsv = -1.0\n",
        "                for j in range(impactStart, i):\n",
        "                    if (maxDtsv < dtsvDataset[j]):\n",
        "                        maxDtsv = dtsvDataset[j]\n",
        "                if (maxDtsv >= DTSV_IMPACT_HIGH):\n",
        "                    # If the DTSV is too highm it is an impact\n",
        "                    impactType = TYPE_IMPACT_HARD\n",
        "                else:\n",
        "                    # Otherwise, it might be force impartion or impact\n",
        "                    areaUnderCurve = simps(tsvDataset[impactStart:i], dx=timeDiffInMs)\n",
        "                    print(\"Area under curve:\", areaUnderCurve)\n",
        "                    if (areaUnderCurve >= FORCE_AREA_MIN):\n",
        "                        # Not actually an impact, just external application of force\n",
        "                        impactType = TYPE_IMPACT_FORCE\n",
        "                    else:\n",
        "                        # Impact it is\n",
        "                        if (maxDtsv >= DTSV_IMPACT_MEDIUM):\n",
        "                            impactType = TYPE_IMPACT_MEDIUM\n",
        "                        elif (maxDtsv >= DTSV_IMPACT_LOW):\n",
        "                            impactType = TYPE_IMPACT_SOFT\n",
        "                        else:\n",
        "                            impactType = TYPE_IMPACT_NEGLIGIBLE\n",
        "                detectedEvents.append([EVENT_IMPACT, impactStart, i, maxTsv, maxDtsv, impactType])\n",
        "\n",
        "                # Noise filtering to be done only for high and medium impacts\n",
        "                if ((impactType == TYPE_IMPACT_HARD) or (impactType == TYPE_IMPACT_MEDIUM)):\n",
        "                    # End of impact, detect noise zone\n",
        "                    if (noiseStart < 0):\n",
        "                        noiseStart = i\n",
        "                    calmZoneCount = 0\n",
        "                impactStart = -1\n",
        "                maxTsv = -1.0\n",
        "            # Initialize stuff if this is the start of freefall\n",
        "            if (freefallStart < 0):\n",
        "                freefallStart = i\n",
        "                minTsv = currentTsv\n",
        "        else:\n",
        "            # Regular zone\n",
        "            # Check for end of noise\n",
        "            if (noiseStart >= 0):\n",
        "                if ((currentTsv <= TSV_CALMZONE_HIGH) and (currentTsv >= TSV_CALMZONE_LOW)):\n",
        "                    calmZoneCount += 1\n",
        "                    if (calmZoneCount >= CALMZONE_DURATION):\n",
        "                        # We have calmed down enough\n",
        "                        noiseZones.append([noiseStart, i])\n",
        "                        noiseStart = -1\n",
        "                        calmZoneCount = 0\n",
        "                else:\n",
        "                    # Still some noise\n",
        "                    calmZoneCount = 0\n",
        "            # Finalize stuff if this marks the end of an impact event\n",
        "            if (impactStart > 0):\n",
        "                # Look at DTSV to determine type\n",
        "                maxDtsv = -1.0\n",
        "                for j in range(impactStart, i):\n",
        "                    if (maxDtsv < dtsvDataset[j]):\n",
        "                        maxDtsv = dtsvDataset[j]\n",
        "                if (maxDtsv >= DTSV_IMPACT_HIGH):\n",
        "                    # If the DTSV is too high, it is an impact\n",
        "                    impactType = TYPE_IMPACT_HARD\n",
        "                else:\n",
        "                    areaUnderCurve = simps(tsvDataset[impactStart:i], dx=timeDiffInMs)\n",
        "                    print(\"Area under curve:\", areaUnderCurve)\n",
        "                    if (areaUnderCurve >= FORCE_AREA_MIN):\n",
        "                        # Not actually an impact, just external application of force\n",
        "                        impactType = TYPE_IMPACT_FORCE\n",
        "                    else:\n",
        "                        # Impact it is\n",
        "                        if (maxDtsv >= DTSV_IMPACT_MEDIUM):\n",
        "                            impactType = TYPE_IMPACT_MEDIUM\n",
        "                        elif (maxDtsv >= DTSV_IMPACT_LOW):\n",
        "                            impactType = TYPE_IMPACT_SOFT\n",
        "                        else:\n",
        "                            impactType = TYPE_IMPACT_NEGLIGIBLE\n",
        "                detectedEvents.append([EVENT_IMPACT, impactStart, i, maxTsv, maxDtsv, impactType])\n",
        "\n",
        "                # Noise filtering to be done only for high and medium impacts\n",
        "                if ((impactType == TYPE_IMPACT_HARD) or (impactType == TYPE_IMPACT_MEDIUM)):\n",
        "                    # End of impact, detect noise zone\n",
        "                    if (noiseStart < 0):\n",
        "                        noiseStart = i\n",
        "                    calmZoneCount = 0\n",
        "                impactStart = -1\n",
        "                maxTsv = -1\n",
        "            # Finalize stuff if this marks the end of a freefall event\n",
        "            if (freefallStart > 0):\n",
        "                spinDetected = detectSpin(tsvDataset, freefallStart, i)\n",
        "                detectedEvents.append([EVENT_FREEFALL, freefallStart, i, minTsv, spinDetected])\n",
        "                freefallStart = -1\n",
        "                minTsv = -1\n",
        "    print(\"Detect Event Count: \"+str(len(detectedEvents)))\n",
        "    print(\"Noise Count: \" +str(len(noiseZones)))\n",
        "    return detectedEvents, noiseZones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukmjlSiAXlnu"
      },
      "source": [
        "### DataFrame generation for model imput"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILoAvMcgXyp1"
      },
      "source": [
        "def prepareTFLiteModelInput(events):\n",
        "    for event in events:\n",
        "        print(len(event))\n",
        "        print(event)\n",
        "    impactEventCount = 0\n",
        "    freeFallEventCount = 0\n",
        "    maxTSV = 0.0\n",
        "    totalTSV = 0.0\n",
        "    avgTSV = 0.0\n",
        "    maxDTSV = 0.0\n",
        "    totalDTSV = 0.0\n",
        "    avgDTSV = 0.0\n",
        "    totalSeverity = 0.0\n",
        "    avgSeverity = 0.0\n",
        "    minTSV = 1000.0\n",
        "    totalMinTSV = 0.0\n",
        "    avgMinTSV = 0.0\n",
        "    totalSpinDetectedEventCount = 0\n",
        "    avgSpin = 0.0\n",
        "\n",
        "    for event in events:\n",
        "\n",
        "        if(len(event)==6):\n",
        "            impactEventCount +=1\n",
        "\n",
        "            totalTSV += event[3]\n",
        "            if (event[3] > maxTSV):\n",
        "                maxTSV = event[3]\n",
        "\n",
        "            totalDTSV += abs(event[4])\n",
        "            if (abs(event[4]) > maxDTSV):\n",
        "                maxDTSV = abs(event[4])\n",
        "\n",
        "            totalSeverity += event[5] / 5.0\n",
        "\n",
        "        elif (len(event)==5):\n",
        "            freeFallEventCount +=1\n",
        "\n",
        "            totalMinTSV += event[3]\n",
        "            if (event[3] < minTSV):\n",
        "                minTSV = event[3]\n",
        "        \n",
        "            if (event[4]):\n",
        "                totalSpinDetectedEventCount +=1\n",
        "            \n",
        "        if (impactEventCount == 0):\n",
        "            impactEventCount = 1\n",
        "        avgTSV = totalTSV / impactEventCount\n",
        "        avgDTSV = totalDTSV / impactEventCount\n",
        "        avgSeverity = totalSeverity / impactEventCount\n",
        "\n",
        "        if (freeFallEventCount == 0):\n",
        "            freeFallEventCount = 1\n",
        "        avgMinTSV = totalMinTSV / freeFallEventCount\n",
        "        avgSpin = totalSpinDetectedEventCount / freeFallEventCount\n",
        "    \n",
        "    if (minTSV == 1000.0):\n",
        "        minTSV = 0.0\n",
        "    outputDataList.append([ maxTSV,maxDTSV,avgTSV,avgDTSV,avgSeverity,minTSV,avgMinTSV,avgSpin,1 ])\n",
        "    #print(\"ModelInput:\", [ maxTSV,maxDTSV,avgTSV,avgDTSV,avgSeverity,minTSV,avgMinTSV,avgSpin])\n",
        "    return [ maxTSV, maxDTSV, avgTSV, avgDTSV, avgSeverity, minTSV, avgMinTSV, avgSpin]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2jZBu5-ZKMj"
      },
      "source": [
        "### Export new DF as an CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1lnJBcdYhUT"
      },
      "source": [
        "def makeOutputDataFrame(folder_name):\n",
        "    df = pd.DataFrame(outputDataList)\n",
        "    df.columns = ['maxTSV','maxDTSV','avgTSV','avgDTSV', 'avgSeverity', 'minTSV','avgMinTSV','avgSpin','result']\n",
        "    dataframe_csv_file_name  = folder_name + '_DataFrame.csv'\n",
        "    df.to_csv(dataframe_csv_file_name, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxdZg95fO3X8"
      },
      "source": [
        "### List of CSV file path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCkxn0k_ZaWz"
      },
      "source": [
        "import os\n",
        "\n",
        "def getAccelerometerDataCsvFilesNamePath(folder_name):\n",
        "    path_array = []\n",
        "    dataFolderPath = folder_name + \"/\"\n",
        "\n",
        "    dirPath = os.path.join(os.getcwd(), dataFolderPath)\n",
        "  \n",
        "    for f in os.listdir(dirPath):\n",
        "\t    if os.path.isfile(os.path.join(dirPath, f)):\n",
        "              path_array.append(\"\".join([folder_name, \"/\", f]))\n",
        "\n",
        "    return path_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2farodDB-YV"
      },
      "source": [
        "### Calculate TSV DTSV & call detectEvents()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K88TtksBOynK"
      },
      "source": [
        "#######################\n",
        "#        MAIN         #\n",
        "#######################\n",
        "def preProcessData(fullFilename):\n",
        "  # 1. Initializations\n",
        "  # fullFilename = 'FSXXXX_2017_11_01_18_32_29  - preimpact.csv'  NOT in USE\n",
        "\n",
        "  # 2. Load raw data\n",
        "  csv_path = os.path.join(os.getcwd(), fullFilename)\n",
        "  fileData = pd.read_csv(csv_path)\n",
        "  fileData[\"TS\"] = fileData[\"TS\"] - fileData[\"TS\"][0]\n",
        "  fileData[\"TS\"] = fileData[\"TS\"] / 1000000\n",
        "  numberOfSamples = fileData[\"TS\"].count()\n",
        "  timeDiffInMs = round(np.median(np.diff(fileData[\"TS\"])))\n",
        "  print(\"Timediff median:\", timeDiffInMs)\n",
        "\n",
        "  print('Number of samples:', numberOfSamples)\n",
        "\n",
        "  # 3. Initialize algorithm parameters\n",
        "  # 3.1. TSV\n",
        "  tsv = list()\n",
        "  dtsv = list()\n",
        "  for i in range(numberOfSamples):\n",
        "      tsv.append(np.sqrt(np.square(fileData[\"X\"][i]) + np.square(fileData[\"Y\"][i]) + np.square(fileData[\"Z\"][i])))\n",
        "\n",
        "  # 3.2. DTSV\n",
        "  dtsv.append(0)\n",
        "  for i in range(1, numberOfSamples):\n",
        "      dtsv.append(tsv[i] - tsv[i - 1])\n",
        "\n",
        "  # 4. Process data\n",
        "  print('Interpolation off')\n",
        "  numberOfInterpolatedSamples = numberOfSamples\n",
        "  tsInterpolated = copy.deepcopy(fileData[\"TS\"][:])\n",
        "  xInterpolated = copy.deepcopy(fileData[\"X\"][:])\n",
        "  yInterpolated = copy.deepcopy(fileData[\"Y\"][:])\n",
        "  zInterpolated = copy.deepcopy(fileData[\"Z\"][:])\n",
        "  tsvInterpolated = copy.deepcopy(tsv[:])\n",
        "  dtsvInterpolated = copy.deepcopy(dtsv[:])\n",
        "\n",
        "  print('Resampling off')\n",
        "  numberOfResampledSamples = numberOfInterpolatedSamples\n",
        "  tsResampled = tsInterpolated[:]\n",
        "  xResampled = xInterpolated[:]\n",
        "  yResampled = yInterpolated[:]\n",
        "  zResampled = zInterpolated[:]\n",
        "  tsvResampled = tsvInterpolated[:]\n",
        "  dtsvResampled = dtsvInterpolated[:] \n",
        "\n",
        "  # 5. Detect events\n",
        "  events, noises = detectEvents(tsResampled, tsvResampled, dtsvResampled)\n",
        "  print(\"Detected events:\", events)\n",
        "  prepareTFLiteModelInput(events)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA208Fm-13CJ"
      },
      "source": [
        "### **Download** data into this colab from cloud & **unzip** data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf69yNWQ18FJ"
      },
      "source": [
        "!curl -L -o DeviceAbuseData.zip https://github.com/arnabalumnus/Zebra/raw/python/python/eventData_LogisticRegration/DeviceAbuseData.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga88v2hI3Eyw"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('DeviceAbuseData.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZGZTRzpZceU"
      },
      "source": [
        "### **DataFrame.csv** file generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02rJasdMbML3"
      },
      "source": [
        "def main(folder):\n",
        "  file_name_list = getAccelerometerDataCsvFilesNamePath(folder)\n",
        "  for file_name in file_name_list:\n",
        "    print(file_name)\n",
        "    preProcessData(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCZoWLcC4NrW"
      },
      "source": [
        "main('FF')\n",
        "makeOutputDataFrame('FF')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjBrkKxU4SA8"
      },
      "source": [
        "main('HF')\n",
        "makeOutputDataFrame('HF')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTrMDUxq4VGK"
      },
      "source": [
        "main('OT')\n",
        "makeOutputDataFrame('OT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awYkTWvr4Y7W"
      },
      "source": [
        "main('PF')\n",
        "makeOutputDataFrame('PF')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNwZ5KGr4b9Z"
      },
      "source": [
        "main('UT')\n",
        "makeOutputDataFrame('UT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCDE005A43ER"
      },
      "source": [
        "main('DS')\n",
        "makeOutputDataFrame('DS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AgBk3Wo45RG"
      },
      "source": [
        "main('FS')\n",
        "makeOutputDataFrame('FS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sXezndT47pD"
      },
      "source": [
        "main('WS')\n",
        "makeOutputDataFrame('WS')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}